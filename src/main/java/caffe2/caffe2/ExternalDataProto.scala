// Generated by the Scala Plugin for the Protocol Buffer Compiler.
// Do not edit!
//
// Protofile syntax: PROTO2

package caffe2.caffe2

/** ExternalDataProto stores the pointer to the content of TensorProto
  * the content are stored in the raw format as little endian
  *
  * @param recordId
  *   used together with type
  * @param recordSize
  *   the size of the entire record (in bytes)
  * @param offset
  *   the offset of the starting point, the content may be shared between
  *   multiple tensors
  * @param strides
  *   the strides of the content
  */
@SerialVersionUID(0L)
final case class ExternalDataProto(
    sourceType: _root_.scala.Option[caffe2.caffe2.ExternalDataProto.SourceType] = _root_.scala.None,
    recordId: _root_.scala.Option[_root_.scala.Predef.String] = _root_.scala.None,
    recordSize: _root_.scala.Option[_root_.scala.Long] = _root_.scala.None,
    offset: _root_.scala.Option[_root_.scala.Long] = _root_.scala.None,
    strides: _root_.scala.Seq[_root_.scala.Long] = _root_.scala.Seq.empty,
    unknownFields: _root_.scalapb.UnknownFieldSet = _root_.scalapb.UnknownFieldSet.empty
    ) extends scalapb.GeneratedMessage with scalapb.lenses.Updatable[ExternalDataProto] {
    @transient
    private[this] var __serializedSizeCachedValue: _root_.scala.Int = 0
    private[this] def __computeSerializedValue(): _root_.scala.Int = {
      var __size = 0
      if (sourceType.isDefined) {
        val __value = sourceType.get.value
        __size += _root_.com.google.protobuf.CodedOutputStream.computeEnumSize(1, __value)
      };
      if (recordId.isDefined) {
        val __value = recordId.get
        __size += _root_.com.google.protobuf.CodedOutputStream.computeStringSize(2, __value)
      };
      if (recordSize.isDefined) {
        val __value = recordSize.get
        __size += _root_.com.google.protobuf.CodedOutputStream.computeUInt64Size(5, __value)
      };
      if (offset.isDefined) {
        val __value = offset.get
        __size += _root_.com.google.protobuf.CodedOutputStream.computeInt64Size(3, __value)
      };
      strides.foreach { __item =>
        val __value = __item
        __size += _root_.com.google.protobuf.CodedOutputStream.computeInt64Size(4, __value)
      }
      __size += unknownFields.serializedSize
      __size
    }
    override def serializedSize: _root_.scala.Int = {
      var read = __serializedSizeCachedValue
      if (read == 0) {
        read = __computeSerializedValue()
        __serializedSizeCachedValue = read
      }
      read
    }
    def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
      sourceType.foreach { __v =>
        val __m = __v.value
        _output__.writeEnum(1, __m)
      };
      recordId.foreach { __v =>
        val __m = __v
        _output__.writeString(2, __m)
      };
      offset.foreach { __v =>
        val __m = __v
        _output__.writeInt64(3, __m)
      };
      strides.foreach { __v =>
        val __m = __v
        _output__.writeInt64(4, __m)
      };
      recordSize.foreach { __v =>
        val __m = __v
        _output__.writeUInt64(5, __m)
      };
      unknownFields.writeTo(_output__)
    }
    def getSourceType: caffe2.caffe2.ExternalDataProto.SourceType = sourceType.getOrElse(caffe2.caffe2.ExternalDataProto.SourceType.INLINE_CONTAINER)
    def clearSourceType: ExternalDataProto = copy(sourceType = _root_.scala.None)
    def withSourceType(__v: caffe2.caffe2.ExternalDataProto.SourceType): ExternalDataProto = copy(sourceType = Option(__v))
    def getRecordId: _root_.scala.Predef.String = recordId.getOrElse("")
    def clearRecordId: ExternalDataProto = copy(recordId = _root_.scala.None)
    def withRecordId(__v: _root_.scala.Predef.String): ExternalDataProto = copy(recordId = Option(__v))
    def getRecordSize: _root_.scala.Long = recordSize.getOrElse(0L)
    def clearRecordSize: ExternalDataProto = copy(recordSize = _root_.scala.None)
    def withRecordSize(__v: _root_.scala.Long): ExternalDataProto = copy(recordSize = Option(__v))
    def getOffset: _root_.scala.Long = offset.getOrElse(0L)
    def clearOffset: ExternalDataProto = copy(offset = _root_.scala.None)
    def withOffset(__v: _root_.scala.Long): ExternalDataProto = copy(offset = Option(__v))
    def clearStrides = copy(strides = _root_.scala.Seq.empty)
    def addStrides(__vs: _root_.scala.Long*): ExternalDataProto = addAllStrides(__vs)
    def addAllStrides(__vs: Iterable[_root_.scala.Long]): ExternalDataProto = copy(strides = strides ++ __vs)
    def withStrides(__v: _root_.scala.Seq[_root_.scala.Long]): ExternalDataProto = copy(strides = __v)
    def withUnknownFields(__v: _root_.scalapb.UnknownFieldSet) = copy(unknownFields = __v)
    def discardUnknownFields = copy(unknownFields = _root_.scalapb.UnknownFieldSet.empty)
    def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
      (__fieldNumber: @_root_.scala.unchecked) match {
        case 1 => sourceType.map(_.javaValueDescriptor).orNull
        case 2 => recordId.orNull
        case 5 => recordSize.orNull
        case 3 => offset.orNull
        case 4 => strides
      }
    }
    def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
      _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
      (__field.number: @_root_.scala.unchecked) match {
        case 1 => sourceType.map(__e => _root_.scalapb.descriptors.PEnum(__e.scalaValueDescriptor)).getOrElse(_root_.scalapb.descriptors.PEmpty)
        case 2 => recordId.map(_root_.scalapb.descriptors.PString(_)).getOrElse(_root_.scalapb.descriptors.PEmpty)
        case 5 => recordSize.map(_root_.scalapb.descriptors.PLong(_)).getOrElse(_root_.scalapb.descriptors.PEmpty)
        case 3 => offset.map(_root_.scalapb.descriptors.PLong(_)).getOrElse(_root_.scalapb.descriptors.PEmpty)
        case 4 => _root_.scalapb.descriptors.PRepeated(strides.iterator.map(_root_.scalapb.descriptors.PLong(_)).toVector)
      }
    }
    def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToUnicodeString(this)
    def companion = caffe2.caffe2.ExternalDataProto
    // @@protoc_insertion_point(GeneratedMessage[caffe2.ExternalDataProto])
}

object ExternalDataProto extends scalapb.GeneratedMessageCompanion[caffe2.caffe2.ExternalDataProto] with scalapb.HasBuilder[caffe2.caffe2.ExternalDataProto] {
  implicit def messageCompanion: scalapb.GeneratedMessageCompanion[caffe2.caffe2.ExternalDataProto] with scalapb.HasBuilder[caffe2.caffe2.ExternalDataProto] = this
  def merge(`_message__`: caffe2.caffe2.ExternalDataProto, `_input__`: _root_.com.google.protobuf.CodedInputStream): caffe2.caffe2.ExternalDataProto = newBuilder(_message__).merge(_input__).result()
  implicit def messageReads: _root_.scalapb.descriptors.Reads[caffe2.caffe2.ExternalDataProto] = _root_.scalapb.descriptors.Reads{
    case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
      _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage == scalaDescriptor), "FieldDescriptor does not match message type.")
      caffe2.caffe2.ExternalDataProto(
        sourceType = __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).flatMap(_.as[_root_.scala.Option[_root_.scalapb.descriptors.EnumValueDescriptor]]).map(__e => caffe2.caffe2.ExternalDataProto.SourceType.fromValue(__e.number)),
        recordId = __fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).flatMap(_.as[_root_.scala.Option[_root_.scala.Predef.String]]),
        recordSize = __fieldsMap.get(scalaDescriptor.findFieldByNumber(5).get).flatMap(_.as[_root_.scala.Option[_root_.scala.Long]]),
        offset = __fieldsMap.get(scalaDescriptor.findFieldByNumber(3).get).flatMap(_.as[_root_.scala.Option[_root_.scala.Long]]),
        strides = __fieldsMap.get(scalaDescriptor.findFieldByNumber(4).get).map(_.as[_root_.scala.Seq[_root_.scala.Long]]).getOrElse(_root_.scala.Seq.empty)
      )
    case _ => throw new RuntimeException("Expected PMessage")
  }
  def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = Caffe2Proto.javaDescriptor.getMessageTypes().get(0)
  def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = Caffe2Proto.scalaDescriptor.messages(0)
  def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[_] = throw new MatchError(__number)
  lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[_ <: _root_.scalapb.GeneratedMessage]] = Seq.empty
  def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[_] = {
    (__fieldNumber: @_root_.scala.unchecked) match {
      case 1 => caffe2.caffe2.ExternalDataProto.SourceType
    }
  }
  lazy val defaultInstance = caffe2.caffe2.ExternalDataProto(
    sourceType = _root_.scala.None,
    recordId = _root_.scala.None,
    recordSize = _root_.scala.None,
    offset = _root_.scala.None,
    strides = _root_.scala.Seq.empty
  )
  final class Builder private (
    private var __sourceType: _root_.scala.Option[caffe2.caffe2.ExternalDataProto.SourceType],
    private var __recordId: _root_.scala.Option[_root_.scala.Predef.String],
    private var __recordSize: _root_.scala.Option[_root_.scala.Long],
    private var __offset: _root_.scala.Option[_root_.scala.Long],
    private val __strides: _root_.scala.collection.immutable.VectorBuilder[_root_.scala.Long],
    private var `_unknownFields__`: _root_.scalapb.UnknownFieldSet.Builder
  ) extends _root_.scalapb.MessageBuilder[caffe2.caffe2.ExternalDataProto] {
    def merge(`_input__`: _root_.com.google.protobuf.CodedInputStream): this.type = {
      var _done__ = false
      while (!_done__) {
        val _tag__ = _input__.readTag()
        _tag__ match {
          case 0 => _done__ = true
          case 8 =>
            __sourceType = Option(caffe2.caffe2.ExternalDataProto.SourceType.fromValue(_input__.readEnum()))
          case 18 =>
            __recordId = Option(_input__.readStringRequireUtf8())
          case 40 =>
            __recordSize = Option(_input__.readUInt64())
          case 24 =>
            __offset = Option(_input__.readInt64())
          case 32 =>
            __strides += _input__.readInt64()
          case 34 => {
            val length = _input__.readRawVarint32()
            val oldLimit = _input__.pushLimit(length)
            while (_input__.getBytesUntilLimit > 0) {
              __strides += _input__.readInt64()
            }
            _input__.popLimit(oldLimit)
          }
          case tag =>
            if (_unknownFields__ == null) {
              _unknownFields__ = new _root_.scalapb.UnknownFieldSet.Builder()
            }
            _unknownFields__.parseField(tag, _input__)
        }
      }
      this
    }
    def result(): caffe2.caffe2.ExternalDataProto = {
      caffe2.caffe2.ExternalDataProto(
        sourceType = __sourceType,
        recordId = __recordId,
        recordSize = __recordSize,
        offset = __offset,
        strides = __strides.result(),
        unknownFields = if (_unknownFields__ == null) _root_.scalapb.UnknownFieldSet.empty else _unknownFields__.result()
      )
    }
  }
  object Builder extends _root_.scalapb.MessageBuilderCompanion[caffe2.caffe2.ExternalDataProto, caffe2.caffe2.ExternalDataProto.Builder] {
    def apply(): Builder = new Builder(
      __sourceType = _root_.scala.None,
      __recordId = _root_.scala.None,
      __recordSize = _root_.scala.None,
      __offset = _root_.scala.None,
      __strides = new _root_.scala.collection.immutable.VectorBuilder[_root_.scala.Long],
      `_unknownFields__` = null
    )
    def apply(`_message__`: caffe2.caffe2.ExternalDataProto): Builder = new Builder(
        __sourceType = _message__.sourceType,
        __recordId = _message__.recordId,
        __recordSize = _message__.recordSize,
        __offset = _message__.offset,
        __strides = new _root_.scala.collection.immutable.VectorBuilder[_root_.scala.Long] ++= _message__.strides,
        `_unknownFields__` = new _root_.scalapb.UnknownFieldSet.Builder(_message__.unknownFields)
    )
  }
  def newBuilder: Builder = caffe2.caffe2.ExternalDataProto.Builder()
  def newBuilder(`_message__`: caffe2.caffe2.ExternalDataProto): Builder = caffe2.caffe2.ExternalDataProto.Builder(_message__)
  /** type of the external storage type, can be the following:
    */
  sealed abstract class SourceType(val value: _root_.scala.Int) extends _root_.scalapb.GeneratedEnum {
    type EnumType = SourceType
    def isInlineContainer: _root_.scala.Boolean = false
    def isSimpleFile: _root_.scala.Boolean = false
    def companion: _root_.scalapb.GeneratedEnumCompanion[SourceType] = caffe2.caffe2.ExternalDataProto.SourceType
    final def asRecognized: _root_.scala.Option[caffe2.caffe2.ExternalDataProto.SourceType.Recognized] = if (isUnrecognized) _root_.scala.None else _root_.scala.Some(this.asInstanceOf[caffe2.caffe2.ExternalDataProto.SourceType.Recognized])
  }
  
  object SourceType extends _root_.scalapb.GeneratedEnumCompanion[SourceType] {
    sealed trait Recognized extends SourceType
    implicit def enumCompanion: _root_.scalapb.GeneratedEnumCompanion[SourceType] = this
    /** the container defined in torch/csrc/jit/serialization.h is used,
      * and record_id is the tag to help the runtime identify the data
      * this type of storage is set as DEFAULT and recommended for external
      * data storage
      */
    @SerialVersionUID(0L)
    case object INLINE_CONTAINER extends SourceType(0) with SourceType.Recognized {
      val index = 0
      val name = "INLINE_CONTAINER"
      override def isInlineContainer: _root_.scala.Boolean = true
    }
    
    /** use external file to store the data, and record_id is the POSIX relative path
      * to the file. this (simple) file is only for the data, and the data is stored
      * as little endian in the file
      */
    @SerialVersionUID(0L)
    case object SIMPLE_FILE extends SourceType(1) with SourceType.Recognized {
      val index = 1
      val name = "SIMPLE_FILE"
      override def isSimpleFile: _root_.scala.Boolean = true
    }
    
    @SerialVersionUID(0L)
    final case class Unrecognized(unrecognizedValue: _root_.scala.Int) extends SourceType(unrecognizedValue) with _root_.scalapb.UnrecognizedEnum
    
    lazy val values = scala.collection.immutable.Seq(INLINE_CONTAINER, SIMPLE_FILE)
    def fromValue(__value: _root_.scala.Int): SourceType = __value match {
      case 0 => INLINE_CONTAINER
      case 1 => SIMPLE_FILE
      case __other => Unrecognized(__other)
    }
    def javaDescriptor: _root_.com.google.protobuf.Descriptors.EnumDescriptor = caffe2.caffe2.ExternalDataProto.javaDescriptor.getEnumTypes().get(0)
    def scalaDescriptor: _root_.scalapb.descriptors.EnumDescriptor = caffe2.caffe2.ExternalDataProto.scalaDescriptor.enums(0)
  }
  implicit class ExternalDataProtoLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, caffe2.caffe2.ExternalDataProto]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, caffe2.caffe2.ExternalDataProto](_l) {
    def sourceType: _root_.scalapb.lenses.Lens[UpperPB, caffe2.caffe2.ExternalDataProto.SourceType] = field(_.getSourceType)((c_, f_) => c_.copy(sourceType = Option(f_)))
    def optionalSourceType: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Option[caffe2.caffe2.ExternalDataProto.SourceType]] = field(_.sourceType)((c_, f_) => c_.copy(sourceType = f_))
    def recordId: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Predef.String] = field(_.getRecordId)((c_, f_) => c_.copy(recordId = Option(f_)))
    def optionalRecordId: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Option[_root_.scala.Predef.String]] = field(_.recordId)((c_, f_) => c_.copy(recordId = f_))
    def recordSize: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Long] = field(_.getRecordSize)((c_, f_) => c_.copy(recordSize = Option(f_)))
    def optionalRecordSize: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Option[_root_.scala.Long]] = field(_.recordSize)((c_, f_) => c_.copy(recordSize = f_))
    def offset: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Long] = field(_.getOffset)((c_, f_) => c_.copy(offset = Option(f_)))
    def optionalOffset: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Option[_root_.scala.Long]] = field(_.offset)((c_, f_) => c_.copy(offset = f_))
    def strides: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Seq[_root_.scala.Long]] = field(_.strides)((c_, f_) => c_.copy(strides = f_))
  }
  final val SOURCE_TYPE_FIELD_NUMBER = 1
  final val RECORD_ID_FIELD_NUMBER = 2
  final val RECORD_SIZE_FIELD_NUMBER = 5
  final val OFFSET_FIELD_NUMBER = 3
  final val STRIDES_FIELD_NUMBER = 4
  def of(
    sourceType: _root_.scala.Option[caffe2.caffe2.ExternalDataProto.SourceType],
    recordId: _root_.scala.Option[_root_.scala.Predef.String],
    recordSize: _root_.scala.Option[_root_.scala.Long],
    offset: _root_.scala.Option[_root_.scala.Long],
    strides: _root_.scala.Seq[_root_.scala.Long]
  ): _root_.caffe2.caffe2.ExternalDataProto = _root_.caffe2.caffe2.ExternalDataProto(
    sourceType,
    recordId,
    recordSize,
    offset,
    strides
  )
  // @@protoc_insertion_point(GeneratedMessageCompanion[caffe2.ExternalDataProto])
}
