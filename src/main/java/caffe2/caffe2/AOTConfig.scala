// Generated by the Scala Plugin for the Protocol Buffer Compiler.
// Do not edit!
//
// Protofile syntax: PROTO2

package caffe2.caffe2

@SerialVersionUID(0L)
final case class AOTConfig(
    maxBatchSize: _root_.scala.Long,
    maxSeqSize: _root_.scala.Long,
    inBatchBroadcast: _root_.scala.Boolean,
    unknownFields: _root_.scalapb.UnknownFieldSet = _root_.scalapb.UnknownFieldSet.empty
    ) extends scalapb.GeneratedMessage with scalapb.lenses.Updatable[AOTConfig] {
    @transient
    private[this] var __serializedSizeCachedValue: _root_.scala.Int = 0
    private[this] def __computeSerializedValue(): _root_.scala.Int = {
      var __size = 0
      
      {
        val __value = maxBatchSize
        __size += _root_.com.google.protobuf.CodedOutputStream.computeInt64Size(1, __value)
      };
      
      {
        val __value = maxSeqSize
        __size += _root_.com.google.protobuf.CodedOutputStream.computeInt64Size(2, __value)
      };
      
      {
        val __value = inBatchBroadcast
        __size += _root_.com.google.protobuf.CodedOutputStream.computeBoolSize(3, __value)
      };
      __size += unknownFields.serializedSize
      __size
    }
    override def serializedSize: _root_.scala.Int = {
      var read = __serializedSizeCachedValue
      if (read == 0) {
        read = __computeSerializedValue()
        __serializedSizeCachedValue = read
      }
      read
    }
    def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
      
      {
        val __v = maxBatchSize
        _output__.writeInt64(1, __v)
      };
      
      {
        val __v = maxSeqSize
        _output__.writeInt64(2, __v)
      };
      
      {
        val __v = inBatchBroadcast
        _output__.writeBool(3, __v)
      };
      unknownFields.writeTo(_output__)
    }
    def withMaxBatchSize(__v: _root_.scala.Long): AOTConfig = copy(maxBatchSize = __v)
    def withMaxSeqSize(__v: _root_.scala.Long): AOTConfig = copy(maxSeqSize = __v)
    def withInBatchBroadcast(__v: _root_.scala.Boolean): AOTConfig = copy(inBatchBroadcast = __v)
    def withUnknownFields(__v: _root_.scalapb.UnknownFieldSet) = copy(unknownFields = __v)
    def discardUnknownFields = copy(unknownFields = _root_.scalapb.UnknownFieldSet.empty)
    def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
      (__fieldNumber: @_root_.scala.unchecked) match {
        case 1 => maxBatchSize
        case 2 => maxSeqSize
        case 3 => inBatchBroadcast
      }
    }
    def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
      _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
      (__field.number: @_root_.scala.unchecked) match {
        case 1 => _root_.scalapb.descriptors.PLong(maxBatchSize)
        case 2 => _root_.scalapb.descriptors.PLong(maxSeqSize)
        case 3 => _root_.scalapb.descriptors.PBoolean(inBatchBroadcast)
      }
    }
    def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToUnicodeString(this)
    def companion = caffe2.caffe2.AOTConfig
    // @@protoc_insertion_point(GeneratedMessage[caffe2.AOTConfig])
}

object AOTConfig extends scalapb.GeneratedMessageCompanion[caffe2.caffe2.AOTConfig] with scalapb.HasBuilder[caffe2.caffe2.AOTConfig] {
  implicit def messageCompanion: scalapb.GeneratedMessageCompanion[caffe2.caffe2.AOTConfig] with scalapb.HasBuilder[caffe2.caffe2.AOTConfig] = this
  def merge(`_message__`: caffe2.caffe2.AOTConfig, `_input__`: _root_.com.google.protobuf.CodedInputStream): caffe2.caffe2.AOTConfig = newBuilder(_message__).merge(_input__).result()
  implicit def messageReads: _root_.scalapb.descriptors.Reads[caffe2.caffe2.AOTConfig] = _root_.scalapb.descriptors.Reads{
    case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
      _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage == scalaDescriptor), "FieldDescriptor does not match message type.")
      caffe2.caffe2.AOTConfig(
        maxBatchSize = __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).get.as[_root_.scala.Long],
        maxSeqSize = __fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).get.as[_root_.scala.Long],
        inBatchBroadcast = __fieldsMap.get(scalaDescriptor.findFieldByNumber(3).get).get.as[_root_.scala.Boolean]
      )
    case _ => throw new RuntimeException("Expected PMessage")
  }
  def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = Caffe2Proto.javaDescriptor.getMessageTypes().get(8)
  def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = Caffe2Proto.scalaDescriptor.messages(8)
  def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[_] = throw new MatchError(__number)
  lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[_ <: _root_.scalapb.GeneratedMessage]] = Seq.empty
  def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[_] = throw new MatchError(__fieldNumber)
  lazy val defaultInstance = caffe2.caffe2.AOTConfig(
    maxBatchSize = 0L,
    maxSeqSize = 0L,
    inBatchBroadcast = false
  )
  final class Builder private (
    private var __maxBatchSize: _root_.scala.Long,
    private var __maxSeqSize: _root_.scala.Long,
    private var __inBatchBroadcast: _root_.scala.Boolean,
    private var `_unknownFields__`: _root_.scalapb.UnknownFieldSet.Builder
  ) extends _root_.scalapb.MessageBuilder[caffe2.caffe2.AOTConfig] {
    private var __requiredFields0: _root_.scala.Long = 0x7L
    def merge(`_input__`: _root_.com.google.protobuf.CodedInputStream): this.type = {
      var _done__ = false
      while (!_done__) {
        val _tag__ = _input__.readTag()
        _tag__ match {
          case 0 => _done__ = true
          case 8 =>
            __maxBatchSize = _input__.readInt64()
            __requiredFields0 &= 0xfffffffffffffffeL
          case 16 =>
            __maxSeqSize = _input__.readInt64()
            __requiredFields0 &= 0xfffffffffffffffdL
          case 24 =>
            __inBatchBroadcast = _input__.readBool()
            __requiredFields0 &= 0xfffffffffffffffbL
          case tag =>
            if (_unknownFields__ == null) {
              _unknownFields__ = new _root_.scalapb.UnknownFieldSet.Builder()
            }
            _unknownFields__.parseField(tag, _input__)
        }
      }
      this
    }
    def result(): caffe2.caffe2.AOTConfig = {
      if (__requiredFields0 != 0L) { throw new _root_.com.google.protobuf.InvalidProtocolBufferException("Message missing required fields.") } 
      caffe2.caffe2.AOTConfig(
        maxBatchSize = __maxBatchSize,
        maxSeqSize = __maxSeqSize,
        inBatchBroadcast = __inBatchBroadcast,
        unknownFields = if (_unknownFields__ == null) _root_.scalapb.UnknownFieldSet.empty else _unknownFields__.result()
      )
    }
  }
  object Builder extends _root_.scalapb.MessageBuilderCompanion[caffe2.caffe2.AOTConfig, caffe2.caffe2.AOTConfig.Builder] {
    def apply(): Builder = new Builder(
      __maxBatchSize = 0L,
      __maxSeqSize = 0L,
      __inBatchBroadcast = false,
      `_unknownFields__` = null
    )
    def apply(`_message__`: caffe2.caffe2.AOTConfig): Builder = new Builder(
        __maxBatchSize = _message__.maxBatchSize,
        __maxSeqSize = _message__.maxSeqSize,
        __inBatchBroadcast = _message__.inBatchBroadcast,
        `_unknownFields__` = new _root_.scalapb.UnknownFieldSet.Builder(_message__.unknownFields)
    )
  }
  def newBuilder: Builder = caffe2.caffe2.AOTConfig.Builder()
  def newBuilder(`_message__`: caffe2.caffe2.AOTConfig): Builder = caffe2.caffe2.AOTConfig.Builder(_message__)
  implicit class AOTConfigLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, caffe2.caffe2.AOTConfig]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, caffe2.caffe2.AOTConfig](_l) {
    def maxBatchSize: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Long] = field(_.maxBatchSize)((c_, f_) => c_.copy(maxBatchSize = f_))
    def maxSeqSize: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Long] = field(_.maxSeqSize)((c_, f_) => c_.copy(maxSeqSize = f_))
    def inBatchBroadcast: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Boolean] = field(_.inBatchBroadcast)((c_, f_) => c_.copy(inBatchBroadcast = f_))
  }
  final val MAX_BATCH_SIZE_FIELD_NUMBER = 1
  final val MAX_SEQ_SIZE_FIELD_NUMBER = 2
  final val IN_BATCH_BROADCAST_FIELD_NUMBER = 3
  def of(
    maxBatchSize: _root_.scala.Long,
    maxSeqSize: _root_.scala.Long,
    inBatchBroadcast: _root_.scala.Boolean
  ): _root_.caffe2.caffe2.AOTConfig = _root_.caffe2.caffe2.AOTConfig(
    maxBatchSize,
    maxSeqSize,
    inBatchBroadcast
  )
  // @@protoc_insertion_point(GeneratedMessageCompanion[caffe2.AOTConfig])
}
