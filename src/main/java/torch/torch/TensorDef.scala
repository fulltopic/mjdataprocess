// Generated by the Scala Plugin for the Protocol Buffer Compiler.
// Do not edit!
//
// Protofile syntax: PROTO2

package torch.torch

/** @param requiresGrad
  *   whether we compute the gradient for the parameter
  * @param device
  *   device field stores the canonical device string, and it follows the
  *   format below: `(cpu|cuda)[:&lt;device-index&gt;]`, e.g., 'cuda:0'
  */
@SerialVersionUID(0L)
final case class TensorDef(
    dims: _root_.scala.Seq[_root_.scala.Long] = _root_.scala.Seq.empty,
    offset: _root_.scala.Option[_root_.scala.Long] = _root_.scala.None,
    strides: _root_.scala.Seq[_root_.scala.Long] = _root_.scala.Seq.empty,
    requiresGrad: _root_.scala.Option[_root_.scala.Boolean] = _root_.scala.None,
    dataType: _root_.scala.Option[caffe2.caffe2.TensorProto.DataType] = _root_.scala.None,
    data: _root_.scala.Option[torch.torch.RecordRef] = _root_.scala.None,
    device: _root_.scala.Option[_root_.scala.Predef.String] = _root_.scala.None,
    isQuantized: _root_.scala.Option[_root_.scala.Boolean] = _root_.scala.None,
    scale: _root_.scala.Option[_root_.scala.Double] = _root_.scala.None,
    zeroPoint: _root_.scala.Option[_root_.scala.Long] = _root_.scala.None,
    unknownFields: _root_.scalapb.UnknownFieldSet = _root_.scalapb.UnknownFieldSet.empty
    ) extends scalapb.GeneratedMessage with scalapb.lenses.Updatable[TensorDef] {
    @transient
    private[this] var __serializedSizeCachedValue: _root_.scala.Int = 0
    private[this] def __computeSerializedValue(): _root_.scala.Int = {
      var __size = 0
      dims.foreach { __item =>
        val __value = __item
        __size += _root_.com.google.protobuf.CodedOutputStream.computeInt64Size(1, __value)
      }
      if (offset.isDefined) {
        val __value = offset.get
        __size += _root_.com.google.protobuf.CodedOutputStream.computeInt64Size(2, __value)
      };
      strides.foreach { __item =>
        val __value = __item
        __size += _root_.com.google.protobuf.CodedOutputStream.computeInt64Size(3, __value)
      }
      if (requiresGrad.isDefined) {
        val __value = requiresGrad.get
        __size += _root_.com.google.protobuf.CodedOutputStream.computeBoolSize(4, __value)
      };
      if (dataType.isDefined) {
        val __value = dataType.get.value
        __size += _root_.com.google.protobuf.CodedOutputStream.computeEnumSize(5, __value)
      };
      if (data.isDefined) {
        val __value = data.get
        __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      };
      if (device.isDefined) {
        val __value = device.get
        __size += _root_.com.google.protobuf.CodedOutputStream.computeStringSize(7, __value)
      };
      if (isQuantized.isDefined) {
        val __value = isQuantized.get
        __size += _root_.com.google.protobuf.CodedOutputStream.computeBoolSize(8, __value)
      };
      if (scale.isDefined) {
        val __value = scale.get
        __size += _root_.com.google.protobuf.CodedOutputStream.computeDoubleSize(9, __value)
      };
      if (zeroPoint.isDefined) {
        val __value = zeroPoint.get
        __size += _root_.com.google.protobuf.CodedOutputStream.computeInt64Size(10, __value)
      };
      __size += unknownFields.serializedSize
      __size
    }
    override def serializedSize: _root_.scala.Int = {
      var read = __serializedSizeCachedValue
      if (read == 0) {
        read = __computeSerializedValue()
        __serializedSizeCachedValue = read
      }
      read
    }
    def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
      dims.foreach { __v =>
        val __m = __v
        _output__.writeInt64(1, __m)
      };
      offset.foreach { __v =>
        val __m = __v
        _output__.writeInt64(2, __m)
      };
      strides.foreach { __v =>
        val __m = __v
        _output__.writeInt64(3, __m)
      };
      requiresGrad.foreach { __v =>
        val __m = __v
        _output__.writeBool(4, __m)
      };
      dataType.foreach { __v =>
        val __m = __v.value
        _output__.writeEnum(5, __m)
      };
      data.foreach { __v =>
        val __m = __v
        _output__.writeTag(6, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
      device.foreach { __v =>
        val __m = __v
        _output__.writeString(7, __m)
      };
      isQuantized.foreach { __v =>
        val __m = __v
        _output__.writeBool(8, __m)
      };
      scale.foreach { __v =>
        val __m = __v
        _output__.writeDouble(9, __m)
      };
      zeroPoint.foreach { __v =>
        val __m = __v
        _output__.writeInt64(10, __m)
      };
      unknownFields.writeTo(_output__)
    }
    def clearDims = copy(dims = _root_.scala.Seq.empty)
    def addDims(__vs: _root_.scala.Long*): TensorDef = addAllDims(__vs)
    def addAllDims(__vs: Iterable[_root_.scala.Long]): TensorDef = copy(dims = dims ++ __vs)
    def withDims(__v: _root_.scala.Seq[_root_.scala.Long]): TensorDef = copy(dims = __v)
    def getOffset: _root_.scala.Long = offset.getOrElse(0L)
    def clearOffset: TensorDef = copy(offset = _root_.scala.None)
    def withOffset(__v: _root_.scala.Long): TensorDef = copy(offset = Option(__v))
    def clearStrides = copy(strides = _root_.scala.Seq.empty)
    def addStrides(__vs: _root_.scala.Long*): TensorDef = addAllStrides(__vs)
    def addAllStrides(__vs: Iterable[_root_.scala.Long]): TensorDef = copy(strides = strides ++ __vs)
    def withStrides(__v: _root_.scala.Seq[_root_.scala.Long]): TensorDef = copy(strides = __v)
    def getRequiresGrad: _root_.scala.Boolean = requiresGrad.getOrElse(false)
    def clearRequiresGrad: TensorDef = copy(requiresGrad = _root_.scala.None)
    def withRequiresGrad(__v: _root_.scala.Boolean): TensorDef = copy(requiresGrad = Option(__v))
    def getDataType: caffe2.caffe2.TensorProto.DataType = dataType.getOrElse(caffe2.caffe2.TensorProto.DataType.UNDEFINED)
    def clearDataType: TensorDef = copy(dataType = _root_.scala.None)
    def withDataType(__v: caffe2.caffe2.TensorProto.DataType): TensorDef = copy(dataType = Option(__v))
    def getData: torch.torch.RecordRef = data.getOrElse(torch.torch.RecordRef.defaultInstance)
    def clearData: TensorDef = copy(data = _root_.scala.None)
    def withData(__v: torch.torch.RecordRef): TensorDef = copy(data = Option(__v))
    def getDevice: _root_.scala.Predef.String = device.getOrElse("")
    def clearDevice: TensorDef = copy(device = _root_.scala.None)
    def withDevice(__v: _root_.scala.Predef.String): TensorDef = copy(device = Option(__v))
    def getIsQuantized: _root_.scala.Boolean = isQuantized.getOrElse(false)
    def clearIsQuantized: TensorDef = copy(isQuantized = _root_.scala.None)
    def withIsQuantized(__v: _root_.scala.Boolean): TensorDef = copy(isQuantized = Option(__v))
    def getScale: _root_.scala.Double = scale.getOrElse(0.0)
    def clearScale: TensorDef = copy(scale = _root_.scala.None)
    def withScale(__v: _root_.scala.Double): TensorDef = copy(scale = Option(__v))
    def getZeroPoint: _root_.scala.Long = zeroPoint.getOrElse(0L)
    def clearZeroPoint: TensorDef = copy(zeroPoint = _root_.scala.None)
    def withZeroPoint(__v: _root_.scala.Long): TensorDef = copy(zeroPoint = Option(__v))
    def withUnknownFields(__v: _root_.scalapb.UnknownFieldSet) = copy(unknownFields = __v)
    def discardUnknownFields = copy(unknownFields = _root_.scalapb.UnknownFieldSet.empty)
    def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
      (__fieldNumber: @_root_.scala.unchecked) match {
        case 1 => dims
        case 2 => offset.orNull
        case 3 => strides
        case 4 => requiresGrad.orNull
        case 5 => dataType.map(_.javaValueDescriptor).orNull
        case 6 => data.orNull
        case 7 => device.orNull
        case 8 => isQuantized.orNull
        case 9 => scale.orNull
        case 10 => zeroPoint.orNull
      }
    }
    def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
      _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
      (__field.number: @_root_.scala.unchecked) match {
        case 1 => _root_.scalapb.descriptors.PRepeated(dims.iterator.map(_root_.scalapb.descriptors.PLong(_)).toVector)
        case 2 => offset.map(_root_.scalapb.descriptors.PLong(_)).getOrElse(_root_.scalapb.descriptors.PEmpty)
        case 3 => _root_.scalapb.descriptors.PRepeated(strides.iterator.map(_root_.scalapb.descriptors.PLong(_)).toVector)
        case 4 => requiresGrad.map(_root_.scalapb.descriptors.PBoolean(_)).getOrElse(_root_.scalapb.descriptors.PEmpty)
        case 5 => dataType.map(__e => _root_.scalapb.descriptors.PEnum(__e.scalaValueDescriptor)).getOrElse(_root_.scalapb.descriptors.PEmpty)
        case 6 => data.map(_.toPMessage).getOrElse(_root_.scalapb.descriptors.PEmpty)
        case 7 => device.map(_root_.scalapb.descriptors.PString(_)).getOrElse(_root_.scalapb.descriptors.PEmpty)
        case 8 => isQuantized.map(_root_.scalapb.descriptors.PBoolean(_)).getOrElse(_root_.scalapb.descriptors.PEmpty)
        case 9 => scale.map(_root_.scalapb.descriptors.PDouble(_)).getOrElse(_root_.scalapb.descriptors.PEmpty)
        case 10 => zeroPoint.map(_root_.scalapb.descriptors.PLong(_)).getOrElse(_root_.scalapb.descriptors.PEmpty)
      }
    }
    def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToUnicodeString(this)
    def companion = torch.torch.TensorDef
    // @@protoc_insertion_point(GeneratedMessage[torch.TensorDef])
}

object TensorDef extends scalapb.GeneratedMessageCompanion[torch.torch.TensorDef] with scalapb.HasBuilder[torch.torch.TensorDef] {
  implicit def messageCompanion: scalapb.GeneratedMessageCompanion[torch.torch.TensorDef] with scalapb.HasBuilder[torch.torch.TensorDef] = this
  def merge(`_message__`: torch.torch.TensorDef, `_input__`: _root_.com.google.protobuf.CodedInputStream): torch.torch.TensorDef = newBuilder(_message__).merge(_input__).result()
  implicit def messageReads: _root_.scalapb.descriptors.Reads[torch.torch.TensorDef] = _root_.scalapb.descriptors.Reads{
    case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
      _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage == scalaDescriptor), "FieldDescriptor does not match message type.")
      torch.torch.TensorDef(
        dims = __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).map(_.as[_root_.scala.Seq[_root_.scala.Long]]).getOrElse(_root_.scala.Seq.empty),
        offset = __fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).flatMap(_.as[_root_.scala.Option[_root_.scala.Long]]),
        strides = __fieldsMap.get(scalaDescriptor.findFieldByNumber(3).get).map(_.as[_root_.scala.Seq[_root_.scala.Long]]).getOrElse(_root_.scala.Seq.empty),
        requiresGrad = __fieldsMap.get(scalaDescriptor.findFieldByNumber(4).get).flatMap(_.as[_root_.scala.Option[_root_.scala.Boolean]]),
        dataType = __fieldsMap.get(scalaDescriptor.findFieldByNumber(5).get).flatMap(_.as[_root_.scala.Option[_root_.scalapb.descriptors.EnumValueDescriptor]]).map(__e => caffe2.caffe2.TensorProto.DataType.fromValue(__e.number)),
        data = __fieldsMap.get(scalaDescriptor.findFieldByNumber(6).get).flatMap(_.as[_root_.scala.Option[torch.torch.RecordRef]]),
        device = __fieldsMap.get(scalaDescriptor.findFieldByNumber(7).get).flatMap(_.as[_root_.scala.Option[_root_.scala.Predef.String]]),
        isQuantized = __fieldsMap.get(scalaDescriptor.findFieldByNumber(8).get).flatMap(_.as[_root_.scala.Option[_root_.scala.Boolean]]),
        scale = __fieldsMap.get(scalaDescriptor.findFieldByNumber(9).get).flatMap(_.as[_root_.scala.Option[_root_.scala.Double]]),
        zeroPoint = __fieldsMap.get(scalaDescriptor.findFieldByNumber(10).get).flatMap(_.as[_root_.scala.Option[_root_.scala.Long]])
      )
    case _ => throw new RuntimeException("Expected PMessage")
  }
  def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = TorchProto.javaDescriptor.getMessageTypes().get(1)
  def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = TorchProto.scalaDescriptor.messages(1)
  def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[_] = {
    var __out: _root_.scalapb.GeneratedMessageCompanion[_] = null
    (__number: @_root_.scala.unchecked) match {
      case 6 => __out = torch.torch.RecordRef
    }
    __out
  }
  lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[_ <: _root_.scalapb.GeneratedMessage]] = Seq.empty
  def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[_] = {
    (__fieldNumber: @_root_.scala.unchecked) match {
      case 5 => caffe2.caffe2.TensorProto.DataType
    }
  }
  lazy val defaultInstance = torch.torch.TensorDef(
    dims = _root_.scala.Seq.empty,
    offset = _root_.scala.None,
    strides = _root_.scala.Seq.empty,
    requiresGrad = _root_.scala.None,
    dataType = _root_.scala.None,
    data = _root_.scala.None,
    device = _root_.scala.None,
    isQuantized = _root_.scala.None,
    scale = _root_.scala.None,
    zeroPoint = _root_.scala.None
  )
  final class Builder private (
    private val __dims: _root_.scala.collection.immutable.VectorBuilder[_root_.scala.Long],
    private var __offset: _root_.scala.Option[_root_.scala.Long],
    private val __strides: _root_.scala.collection.immutable.VectorBuilder[_root_.scala.Long],
    private var __requiresGrad: _root_.scala.Option[_root_.scala.Boolean],
    private var __dataType: _root_.scala.Option[caffe2.caffe2.TensorProto.DataType],
    private var __data: _root_.scala.Option[torch.torch.RecordRef],
    private var __device: _root_.scala.Option[_root_.scala.Predef.String],
    private var __isQuantized: _root_.scala.Option[_root_.scala.Boolean],
    private var __scale: _root_.scala.Option[_root_.scala.Double],
    private var __zeroPoint: _root_.scala.Option[_root_.scala.Long],
    private var `_unknownFields__`: _root_.scalapb.UnknownFieldSet.Builder
  ) extends _root_.scalapb.MessageBuilder[torch.torch.TensorDef] {
    def merge(`_input__`: _root_.com.google.protobuf.CodedInputStream): this.type = {
      var _done__ = false
      while (!_done__) {
        val _tag__ = _input__.readTag()
        _tag__ match {
          case 0 => _done__ = true
          case 8 =>
            __dims += _input__.readInt64()
          case 10 => {
            val length = _input__.readRawVarint32()
            val oldLimit = _input__.pushLimit(length)
            while (_input__.getBytesUntilLimit > 0) {
              __dims += _input__.readInt64()
            }
            _input__.popLimit(oldLimit)
          }
          case 16 =>
            __offset = Option(_input__.readInt64())
          case 24 =>
            __strides += _input__.readInt64()
          case 26 => {
            val length = _input__.readRawVarint32()
            val oldLimit = _input__.pushLimit(length)
            while (_input__.getBytesUntilLimit > 0) {
              __strides += _input__.readInt64()
            }
            _input__.popLimit(oldLimit)
          }
          case 32 =>
            __requiresGrad = Option(_input__.readBool())
          case 40 =>
            __dataType = Option(caffe2.caffe2.TensorProto.DataType.fromValue(_input__.readEnum()))
          case 50 =>
            __data = Option(__data.fold(_root_.scalapb.LiteParser.readMessage[torch.torch.RecordRef](_input__))(_root_.scalapb.LiteParser.readMessage(_input__, _)))
          case 58 =>
            __device = Option(_input__.readStringRequireUtf8())
          case 64 =>
            __isQuantized = Option(_input__.readBool())
          case 73 =>
            __scale = Option(_input__.readDouble())
          case 80 =>
            __zeroPoint = Option(_input__.readInt64())
          case tag =>
            if (_unknownFields__ == null) {
              _unknownFields__ = new _root_.scalapb.UnknownFieldSet.Builder()
            }
            _unknownFields__.parseField(tag, _input__)
        }
      }
      this
    }
    def result(): torch.torch.TensorDef = {
      torch.torch.TensorDef(
        dims = __dims.result(),
        offset = __offset,
        strides = __strides.result(),
        requiresGrad = __requiresGrad,
        dataType = __dataType,
        data = __data,
        device = __device,
        isQuantized = __isQuantized,
        scale = __scale,
        zeroPoint = __zeroPoint,
        unknownFields = if (_unknownFields__ == null) _root_.scalapb.UnknownFieldSet.empty else _unknownFields__.result()
      )
    }
  }
  object Builder extends _root_.scalapb.MessageBuilderCompanion[torch.torch.TensorDef, torch.torch.TensorDef.Builder] {
    def apply(): Builder = new Builder(
      __dims = new _root_.scala.collection.immutable.VectorBuilder[_root_.scala.Long],
      __offset = _root_.scala.None,
      __strides = new _root_.scala.collection.immutable.VectorBuilder[_root_.scala.Long],
      __requiresGrad = _root_.scala.None,
      __dataType = _root_.scala.None,
      __data = _root_.scala.None,
      __device = _root_.scala.None,
      __isQuantized = _root_.scala.None,
      __scale = _root_.scala.None,
      __zeroPoint = _root_.scala.None,
      `_unknownFields__` = null
    )
    def apply(`_message__`: torch.torch.TensorDef): Builder = new Builder(
        __dims = new _root_.scala.collection.immutable.VectorBuilder[_root_.scala.Long] ++= _message__.dims,
        __offset = _message__.offset,
        __strides = new _root_.scala.collection.immutable.VectorBuilder[_root_.scala.Long] ++= _message__.strides,
        __requiresGrad = _message__.requiresGrad,
        __dataType = _message__.dataType,
        __data = _message__.data,
        __device = _message__.device,
        __isQuantized = _message__.isQuantized,
        __scale = _message__.scale,
        __zeroPoint = _message__.zeroPoint,
        `_unknownFields__` = new _root_.scalapb.UnknownFieldSet.Builder(_message__.unknownFields)
    )
  }
  def newBuilder: Builder = torch.torch.TensorDef.Builder()
  def newBuilder(`_message__`: torch.torch.TensorDef): Builder = torch.torch.TensorDef.Builder(_message__)
  implicit class TensorDefLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, torch.torch.TensorDef]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, torch.torch.TensorDef](_l) {
    def dims: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Seq[_root_.scala.Long]] = field(_.dims)((c_, f_) => c_.copy(dims = f_))
    def offset: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Long] = field(_.getOffset)((c_, f_) => c_.copy(offset = Option(f_)))
    def optionalOffset: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Option[_root_.scala.Long]] = field(_.offset)((c_, f_) => c_.copy(offset = f_))
    def strides: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Seq[_root_.scala.Long]] = field(_.strides)((c_, f_) => c_.copy(strides = f_))
    def requiresGrad: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Boolean] = field(_.getRequiresGrad)((c_, f_) => c_.copy(requiresGrad = Option(f_)))
    def optionalRequiresGrad: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Option[_root_.scala.Boolean]] = field(_.requiresGrad)((c_, f_) => c_.copy(requiresGrad = f_))
    def dataType: _root_.scalapb.lenses.Lens[UpperPB, caffe2.caffe2.TensorProto.DataType] = field(_.getDataType)((c_, f_) => c_.copy(dataType = Option(f_)))
    def optionalDataType: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Option[caffe2.caffe2.TensorProto.DataType]] = field(_.dataType)((c_, f_) => c_.copy(dataType = f_))
    def data: _root_.scalapb.lenses.Lens[UpperPB, torch.torch.RecordRef] = field(_.getData)((c_, f_) => c_.copy(data = Option(f_)))
    def optionalData: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Option[torch.torch.RecordRef]] = field(_.data)((c_, f_) => c_.copy(data = f_))
    def device: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Predef.String] = field(_.getDevice)((c_, f_) => c_.copy(device = Option(f_)))
    def optionalDevice: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Option[_root_.scala.Predef.String]] = field(_.device)((c_, f_) => c_.copy(device = f_))
    def isQuantized: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Boolean] = field(_.getIsQuantized)((c_, f_) => c_.copy(isQuantized = Option(f_)))
    def optionalIsQuantized: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Option[_root_.scala.Boolean]] = field(_.isQuantized)((c_, f_) => c_.copy(isQuantized = f_))
    def scale: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Double] = field(_.getScale)((c_, f_) => c_.copy(scale = Option(f_)))
    def optionalScale: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Option[_root_.scala.Double]] = field(_.scale)((c_, f_) => c_.copy(scale = f_))
    def zeroPoint: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Long] = field(_.getZeroPoint)((c_, f_) => c_.copy(zeroPoint = Option(f_)))
    def optionalZeroPoint: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Option[_root_.scala.Long]] = field(_.zeroPoint)((c_, f_) => c_.copy(zeroPoint = f_))
  }
  final val DIMS_FIELD_NUMBER = 1
  final val OFFSET_FIELD_NUMBER = 2
  final val STRIDES_FIELD_NUMBER = 3
  final val REQUIRES_GRAD_FIELD_NUMBER = 4
  final val DATA_TYPE_FIELD_NUMBER = 5
  final val DATA_FIELD_NUMBER = 6
  final val DEVICE_FIELD_NUMBER = 7
  final val IS_QUANTIZED_FIELD_NUMBER = 8
  final val SCALE_FIELD_NUMBER = 9
  final val ZERO_POINT_FIELD_NUMBER = 10
  def of(
    dims: _root_.scala.Seq[_root_.scala.Long],
    offset: _root_.scala.Option[_root_.scala.Long],
    strides: _root_.scala.Seq[_root_.scala.Long],
    requiresGrad: _root_.scala.Option[_root_.scala.Boolean],
    dataType: _root_.scala.Option[caffe2.caffe2.TensorProto.DataType],
    data: _root_.scala.Option[torch.torch.RecordRef],
    device: _root_.scala.Option[_root_.scala.Predef.String],
    isQuantized: _root_.scala.Option[_root_.scala.Boolean],
    scale: _root_.scala.Option[_root_.scala.Double],
    zeroPoint: _root_.scala.Option[_root_.scala.Long]
  ): _root_.torch.torch.TensorDef = _root_.torch.torch.TensorDef(
    dims,
    offset,
    strides,
    requiresGrad,
    dataType,
    data,
    device,
    isQuantized,
    scale,
    zeroPoint
  )
  // @@protoc_insertion_point(GeneratedMessageCompanion[torch.TensorDef])
}
